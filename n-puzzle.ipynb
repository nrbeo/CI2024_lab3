{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 3 - N-Puzzle "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Tuple\n",
    "from collections import namedtuple\n",
    "from random import choice\n",
    "import numpy as np\n",
    "import heapq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the dimension of the puzzle (e.g., 3x3 grid)\n",
    "PUZZLE_DIM = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "def available_actions(state: np.ndarray) -> List[Tuple[int, int]]:\n",
    "    \"\"\"\n",
    "    Determines all valid moves for the blank tile (0) in the given puzzle state.\n",
    "\n",
    "    Parameters:\n",
    "    - state (np.ndarray): The current configuration of the puzzle.\n",
    "\n",
    "    Returns:\n",
    "    - List[Tuple[int, int]]: A list of valid moves as (row_offset, col_offset).\n",
    "    \"\"\"\n",
    "    row, col = np.where(state == 0)  # Locate the blank tile\n",
    "    row, col = row[0], col[0]  # Unpack row and column values\n",
    "    moves = []\n",
    "    if row > 0: moves.append((-1, 0))  # Move blank up\n",
    "    if row < state.shape[0] - 1: moves.append((1, 0))  # Move blank down\n",
    "    if col > 0: moves.append((0, -1))  # Move blank left\n",
    "    if col < state.shape[1] - 1: moves.append((0, 1))  # Move blank right\n",
    "    return moves\n",
    "\n",
    "\n",
    "def apply_action(state: np.ndarray, move: Tuple[int, int]) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Executes a specified move, updating the puzzle state by swapping tiles.\n",
    "\n",
    "    Parameters:\n",
    "    - state (np.ndarray): The current configuration of the puzzle.\n",
    "    - move (Tuple[int, int]): The move as (row_offset, col_offset).\n",
    "\n",
    "    Returns:\n",
    "    - np.ndarray: A new puzzle configuration after the move is applied.\n",
    "    \"\"\"\n",
    "    row, col = np.where(state == 0)  # Locate the blank tile\n",
    "    row, col = row[0], col[0]  # Unpack row and column values\n",
    "    new_state = state.copy()\n",
    "    new_row, new_col = row + move[0], col + move[1]  # Apply the move offsets\n",
    "    # Swap the blank tile with the target tile\n",
    "    new_state[row, col], new_state[new_row, new_col] = new_state[new_row, new_col], new_state[row, col]\n",
    "    return new_state\n",
    "\n",
    "\n",
    "def generate_solvable_puzzle(goal_state: np.ndarray, num_steps: int = 100000) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Generates a randomized but solvable configuration of the puzzle by applying\n",
    "    a series of valid moves starting from the goal state.\n",
    "\n",
    "    Parameters:\n",
    "    - goal_state (np.ndarray): The solved configuration of the puzzle.\n",
    "    - num_moves (int): The number of random moves to apply.\n",
    "\n",
    "    Returns:\n",
    "    - np.ndarray: A randomized, solvable puzzle state.\n",
    "    \"\"\"\n",
    "    # Start with the goal state\n",
    "    current_state = goal_state.copy()\n",
    "    \n",
    "    # Apply the specified number of random valid moves\n",
    "    for _ in range(num_steps):\n",
    "        valid_moves = available_actions(current_state)  # Determine valid moves\n",
    "        selected_move = choice(valid_moves)  # Randomly pick one move\n",
    "        current_state = apply_action(current_state, selected_move)  # Apply the move\n",
    "    \n",
    "    # Return the randomized solvable state\n",
    "    return current_state\n",
    "\n",
    "    \n",
    "\n",
    "def manhattan_distance(state: np.ndarray, goal_state: np.ndarray) -> int:\n",
    "    \"\"\"\n",
    "    Calculates the Manhattan distance heuristic for the current state.\n",
    "\n",
    "    Parameters:\n",
    "    - state (np.ndarray): The current puzzle configuration.\n",
    "    - goal_state (np.ndarray): The target puzzle configuration.\n",
    "\n",
    "    Returns:\n",
    "    - int: The sum of Manhattan distances for all tiles.\n",
    "    \"\"\"\n",
    "    positions = {value: (x, y) for x, row in enumerate(goal_state) for y, value in enumerate(row)}\n",
    "    total_distance = sum(\n",
    "        abs(x - positions[value][0]) + abs(y - positions[value][1])\n",
    "        for x, row in enumerate(state) for y, value in enumerate(row) if value != 0\n",
    "    )\n",
    "    return total_distance\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "def a_star(start_state: np.ndarray, goal_state: np.ndarray) -> Tuple[List[np.ndarray], int, int]:\n",
    "    \"\"\"\n",
    "    Solves the sliding puzzle using the optimized A* algorithm.\n",
    "\n",
    "    Parameters:\n",
    "    - start_state (np.ndarray): The initial puzzle configuration.\n",
    "    - goal_state (np.ndarray): The target puzzle configuration.\n",
    "\n",
    "    Returns:\n",
    "    - Tuple[List[np.ndarray], int, int]:\n",
    "      - A list of states leading to the solution.\n",
    "      - The number of moves to solve the puzzle.\n",
    "      - The total number of explored nodes.\n",
    "    \"\"\"\n",
    "    # Initialize the priority queue (frontier)\n",
    "    # Each element is a tuple: (f_cost, binary_state, current_state)\n",
    "    frontier = []\n",
    "    heapq.heappush(frontier, (0, start_state.tobytes(), start_state))\n",
    "\n",
    "    # Structures for tracking visited states and reconstructing the path\n",
    "    explored = set()  # Keeps track of explored states to avoid revisiting\n",
    "    parent_map = {start_state.tobytes(): None}  # Maps each state's binary representation to its predecessor\n",
    "    g_costs = {start_state.tobytes(): 0}  # Tracks the actual cost (g(n)) to reach each state\n",
    "\n",
    "    nodes_explored = 0  # Counter for the total number of nodes expanded\n",
    "\n",
    "    while frontier:\n",
    "        # Retrieve the state with the lowest f(n) from the priority queue\n",
    "        f_cost, current_bytes, current_state = heapq.heappop(frontier)\n",
    "\n",
    "        # Skip the state if it has already been explored\n",
    "        if current_bytes in explored:\n",
    "            continue\n",
    "\n",
    "        # Check if the current state matches the goal state\n",
    "        if np.array_equal(current_state, goal_state):\n",
    "            # Reconstruct the solution path by backtracking through parent_map\n",
    "            path = []\n",
    "            while current_bytes is not None:\n",
    "                path.append(current_state)\n",
    "                current_bytes = parent_map[current_bytes]  # Move to the parent state\n",
    "                if current_bytes:  # If a parent exists, reconstruct its NumPy array\n",
    "                    current_state = np.frombuffer(current_bytes, dtype=start_state.dtype).reshape(start_state.shape)\n",
    "            path.reverse()  # Reverse the path to get the correct order (start -> goal)\n",
    "            return path, len(path) - 1, nodes_explored  # Return path, moves, and explored nodes\n",
    "\n",
    "        # Mark the current state as explored\n",
    "        explored.add(current_bytes)\n",
    "        nodes_explored += 1\n",
    "\n",
    "        # Generate all valid neighbors (states reachable in one move)\n",
    "        for move in available_actions(current_state):\n",
    "            # Apply the move to generate the next state\n",
    "            next_state = apply_action(current_state, move)\n",
    "            next_bytes = next_state.tobytes()  # Convert the state to its binary representation\n",
    "\n",
    "            # Calculate g(n) for the neighbor\n",
    "            tentative_g_cost = g_costs[current_bytes] + 1  # Increment cost by 1 for each move\n",
    "\n",
    "            # If the state hasn't been visited or a better path is found\n",
    "            if next_bytes not in g_costs or tentative_g_cost < g_costs[next_bytes]:\n",
    "                g_costs[next_bytes] = tentative_g_cost  # Update the g(n) value\n",
    "                h_cost = manhattan_distance(next_state, goal_state)  # Compute the heuristic (h(n))\n",
    "                f_cost = tentative_g_cost + h_cost  # Total estimated cost f(n) = g(n) + h(n)\n",
    "                heapq.heappush(frontier, (f_cost, next_bytes, next_state))  # Add the state to the frontier\n",
    "                parent_map[next_bytes] = current_bytes  # Track its parent for path reconstruction\n",
    "\n",
    "    # If the goal state is not reachable, return an empty solution\n",
    "    return [], 0, nodes_explored\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Solution Path (20 moves, 309 nodes explored):\n",
      "Step 0:\n",
      "[[1 5 8]\n",
      " [4 6 2]\n",
      " [0 3 7]]\n",
      "\n",
      "Step 1:\n",
      "[[1 5 8]\n",
      " [0 6 2]\n",
      " [4 3 7]]\n",
      "\n",
      "Step 2:\n",
      "[[0 5 8]\n",
      " [1 6 2]\n",
      " [4 3 7]]\n",
      "\n",
      "Step 3:\n",
      "[[5 0 8]\n",
      " [1 6 2]\n",
      " [4 3 7]]\n",
      "\n",
      "Step 4:\n",
      "[[5 8 0]\n",
      " [1 6 2]\n",
      " [4 3 7]]\n",
      "\n",
      "Step 5:\n",
      "[[5 8 2]\n",
      " [1 6 0]\n",
      " [4 3 7]]\n",
      "\n",
      "Step 6:\n",
      "[[5 8 2]\n",
      " [1 0 6]\n",
      " [4 3 7]]\n",
      "\n",
      "Step 7:\n",
      "[[5 8 2]\n",
      " [1 3 6]\n",
      " [4 0 7]]\n",
      "\n",
      "Step 8:\n",
      "[[5 8 2]\n",
      " [1 3 6]\n",
      " [4 7 0]]\n",
      "\n",
      "Step 9:\n",
      "[[5 8 2]\n",
      " [1 3 0]\n",
      " [4 7 6]]\n",
      "\n",
      "Step 10:\n",
      "[[5 8 2]\n",
      " [1 0 3]\n",
      " [4 7 6]]\n",
      "\n",
      "Step 11:\n",
      "[[5 0 2]\n",
      " [1 8 3]\n",
      " [4 7 6]]\n",
      "\n",
      "Step 12:\n",
      "[[0 5 2]\n",
      " [1 8 3]\n",
      " [4 7 6]]\n",
      "\n",
      "Step 13:\n",
      "[[1 5 2]\n",
      " [0 8 3]\n",
      " [4 7 6]]\n",
      "\n",
      "Step 14:\n",
      "[[1 5 2]\n",
      " [4 8 3]\n",
      " [0 7 6]]\n",
      "\n",
      "Step 15:\n",
      "[[1 5 2]\n",
      " [4 8 3]\n",
      " [7 0 6]]\n",
      "\n",
      "Step 16:\n",
      "[[1 5 2]\n",
      " [4 0 3]\n",
      " [7 8 6]]\n",
      "\n",
      "Step 17:\n",
      "[[1 0 2]\n",
      " [4 5 3]\n",
      " [7 8 6]]\n",
      "\n",
      "Step 18:\n",
      "[[1 2 0]\n",
      " [4 5 3]\n",
      " [7 8 6]]\n",
      "\n",
      "Step 19:\n",
      "[[1 2 3]\n",
      " [4 5 0]\n",
      " [7 8 6]]\n",
      "\n",
      "Step 20:\n",
      "[[1 2 3]\n",
      " [4 5 6]\n",
      " [7 8 0]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "goal_state = np.array([i for i in range(1, PUZZLE_DIM**2)] + [0]).reshape((PUZZLE_DIM, PUZZLE_DIM))\n",
    "initial_state = generate_solvable_puzzle(goal_state)\n",
    "\n",
    "# Solve and print the results\n",
    "solution, moves, explored = a_star(initial_state, goal_state)\n",
    "print(f\"Solution Path ({moves} moves, {explored} nodes explored):\")\n",
    "for step, s in enumerate(solution):\n",
    "    print(f\"Step {step}:\\n{s}\\n\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "poetry-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
